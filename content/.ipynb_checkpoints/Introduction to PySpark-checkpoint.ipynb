{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Spark was designed as a computing platform to be fast, general-purpose, and easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PySpark** is a great language for performing exploratory data analysis at scale, building machine learning pipelines, and creating ETLs for a data platform. \n",
    "\n",
    "If youâ€™re already familiar with Python and libraries such as Pandas, then PySpark is a great language to learn in order to create more scalable analyses and pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wiej9SoUfqKq"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"Intro_to_pyspark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMaA036BfiIc"
   },
   "source": [
    "Retrieve SparkContext version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "77j2zUYwfop-",
    "outputId": "3efac232-44d4-45b9-df8a-552ee323bef8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5FrK1BfgJzq"
   },
   "source": [
    "Retrieve Python version of SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f9F8Dz2TgRaB",
    "outputId": "c2e0f82a-7115-4a4f-d277-0abc25e340dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.pythonVer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pw6YiRV2gVul"
   },
   "source": [
    "URL of the cluster or \"local\" string to run in local mode of SparkContex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HfuD-eyJgTbI",
    "outputId": "4d173334-a389-4625-a3ec-e66918b4ce83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3EX3WSqWgkpX"
   },
   "source": [
    "# Loading data in PySpark\n",
    "SparkContext's *paralleliza()* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3RPhDgEgf4P"
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4rb5WsH-g-vv"
   },
   "source": [
    "SparksContext's *textFile()* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzqL0xQAg31b"
   },
   "outputs": [],
   "source": [
    "rdd2 = sc.textFile(\"sample_data/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MpNJsWg0hw8t"
   },
   "source": [
    "Your Turn:\n",
    "\n",
    "\n",
    "*   Print the version of SparkContext in the PySpark shell.\n",
    "*   Print the Python version of SparkContext in the PySpark shell.\n",
    "*   What is the master of SparkContext in the PySpark shell?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3v0RBzXKhVXp"
   },
   "outputs": [],
   "source": [
    "# Print the version of SparkContext\n",
    "print(\"The version of Spark Context in the PySpark shell is\", sc.____)\n",
    "\n",
    "# Print the Python version of SparkContext\n",
    "print(\"The Python version of Spark Context in the PySpark shell is\", sc.____)\n",
    "\n",
    "# Print the master of SparkContext\n",
    "print(\"The master of Spark Context in the PySpark shell is\", sc.____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljH69DxWiNio"
   },
   "source": [
    "* Create a python list named numb containing the numbers 1 to 100.\n",
    "* Load the list into Spark using Spark Context's parallelize method and assign it to a variable spark_data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKQ1PmqTiU-U"
   },
   "outputs": [],
   "source": [
    "# Create a python list of numbers from 1 to 100 \n",
    "numb = range(____, ____)\n",
    "\n",
    "# Load the list into PySpark  \n",
    "spark_data = sc.____(numb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OxRId6UXiY7i"
   },
   "source": [
    "\n",
    "\n",
    "*   Load a local text file sample_data/README.md in PySpark shell.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9o6w5iRmipnD"
   },
   "outputs": [],
   "source": [
    "file_path = 'sample_data/README.md'\n",
    "# Load a local file into PySpark shell\n",
    "lines = sc.____(file_path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.Intro_to_pyspark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
