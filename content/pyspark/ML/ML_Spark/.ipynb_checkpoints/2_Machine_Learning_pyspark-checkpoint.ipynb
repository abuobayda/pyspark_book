{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.6.tgz\n",
    "!tar xvf spark-2.4.4-bin-hadoop2.6.tgz\n",
    "!pip install -q findspark\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.6\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"PySpark_dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s7STP-rXAMW_",
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPWhj_H3BW52",
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[2]') \\\n",
    "        .appName('first_spark_ML_application') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmkXnrIIiRan"
   },
   "source": [
    "![alt text](https://learning.oreilly.com/library/view/spark-the-definitive/9781491912201/assets/spdg_2402.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkqhSCukyZCj"
   },
   "source": [
    "## What is PySpark MLlib?\n",
    "Spark MLlib is short for spark machine learning library. Machine learning in PySpark is easy to use and scalable. It works on distributed systems. We use in Spark machine learning for data analysis. We get the benefit of various machine learning algorithms such as Regression, classification etc, because of the PySpark MLlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMMCpMm2BY8w"
   },
   "source": [
    "## Data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yg_UFR4gC5nm"
   },
   "source": [
    "### flight dataset \n",
    "Some airline flight data stored in a csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPUJuR68C9xT"
   },
   "source": [
    "#### Data dictionary\n",
    "mon --> month (integer between 1 and 12)\n",
    "\n",
    "dom --> day of month (integer between 1 and 31)\n",
    "\n",
    "dow --> day of week (integer; 1 = Monday and 7 = Sunday)\n",
    "\n",
    "org --> origin airport (IATA code)\n",
    "\n",
    "mile --> distance (miles)\n",
    "\n",
    "carrier --> carrier (IATA code)\n",
    "\n",
    "depart --> departure time (decimal hour)\n",
    "\n",
    "duration --> expected duration (minutes)\n",
    "\n",
    "delay --> delay (minutes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IH8FzACYD0rP"
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ERiWKZCMDgct"
   },
   "source": [
    "**Creating a SparkSession**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "otxPHJuoD6Tb",
    "outputId": "8c0d3d38-cf75-4ed5-e0d6-80ca1dd97094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 50000 records.\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65| null|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mon', 'int'),\n",
       " ('dom', 'int'),\n",
       " ('dow', 'int'),\n",
       " ('carrier', 'string'),\n",
       " ('flight', 'int'),\n",
       " ('org', 'string'),\n",
       " ('mile', 'int'),\n",
       " ('depart', 'double'),\n",
       " ('duration', 'int'),\n",
       " ('delay', 'int')]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from CSV file\n",
    "flights = spark.read.csv('flights.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')\n",
    "\n",
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % flights.count())\n",
    "\n",
    "# View the first five records\n",
    "flights.show(5)\n",
    "\n",
    "# Check column data types\n",
    "flights.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eqiVQTaSUNo_"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "P9e8ULJTHM_9",
    "outputId": "08d7ce08-a44b-4edd-dbd3-4c9b5e701c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65| null|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ox1j_-gtKJEr"
   },
   "source": [
    "#### Removing columns and Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5A5bHIxHsUG"
   },
   "source": [
    "Do we needs all the columns?\n",
    "* Removing an informative column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MICKQwTMUIjH"
   },
   "source": [
    "In any machine learning project, we always have a few columns that are not required for solving the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_y-QBu87HJsN"
   },
   "outputs": [],
   "source": [
    "# Remove the 'flight' column\n",
    "flights = flights.drop('flight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_2z5nfhAI_nt"
   },
   "source": [
    "Filtering out missing data\n",
    "* removing rows which do not have information about whether or not a flight was delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJ9CMetaUVdX"
   },
   "source": [
    "It is important to check the number of missing values present in all the columns. Knowing the count helps us treat the missing values before building any machine learning model using that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UNYwjZ66Ix9y",
    "outputId": "889e3b49-6859-4286-da71-da941471e756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2978"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records with missing 'delay' values\n",
    "flights.filter('delay IS NULL').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IgFw5tGCJVcf"
   },
   "outputs": [],
   "source": [
    "# Remove records with missing 'delay' values\n",
    "flights = flights.filter('delay IS NOT NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LazHQdDNJk51",
    "outputId": "07b459b7-790b-4ea1-9d4e-1da57ac8bccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47022\n"
     ]
    }
   ],
   "source": [
    "# Remove records with missing values in any column and get the number of remaining rows\n",
    "flights = flights.dropna()\n",
    "print(flights.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJ3qjwBPKPIu"
   },
   "source": [
    "#### Column manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDryILCGKNug"
   },
   "source": [
    "The Federal Aviation Administration (FAA) considers a flight to be \"delayed\" when it arrives **15 minutes or more** after its scheduled time.\n",
    "\n",
    "The next step of preparing the flight data has two parts:\n",
    "\n",
    "1. convert the units of distance, replacing the mile column with a kmcolumn; and\n",
    "2. create a Boolean column indicating whether or not a flight was delayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "TWypq7n9Julz",
    "outputId": "ab3b778b-3849-4a4b-d944-92ddd723d0bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the round function\n",
    "from pyspark.sql.functions import round\n",
    "\n",
    "# Convert 'mile' to 'km' and drop 'mile' column\n",
    "# we use cast function to convert from boolean to integer (0 and 1)\n",
    "flights_km = flights.withColumn('km', round(flights.mile * 1.60934, 0)) \\\n",
    "                    .drop('mile')\n",
    "\n",
    "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
    "# Cast convert boolean value to integer\n",
    "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\n",
    "\n",
    "# Check first five records\n",
    "flights_km.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqFUa6ofM95F"
   },
   "source": [
    "#### Categorical columns\n",
    "Categorical variables represent types of data which may be divided into groups. Examples of categorical variables are race, sex, age group, and educational level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IpHNeYWvUkw7"
   },
   "source": [
    "Most machine learning algorithms accept the data only in numerical form. So, it is essential to convert any categorical variables present in our dataset into numbers.\n",
    "\n",
    "Remember that we cannot simply drop them from our dataset as they might contain useful information. It would be a nightmare to lose that just because we don’t want to figure out how to use them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xq67iTGZNSYx"
   },
   "source": [
    "In the flights data there are two columns, carrier and org, which hold categorical data. We need to transform these columns into indexed numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yra6Rn_gSn5M"
   },
   "source": [
    "* Import the appropriate class and create an indexer object to transform the carrier column from a string to an numeric index.\n",
    "* Prepare the indexer object on the flight data.\n",
    "* Use the prepared indexer to create the numeric index column.\n",
    "* Repeat the process for the org column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kt7UvCjuU58M"
   },
   "source": [
    "**StringIndexer** assigns a unique integer value to each category. 0 is assigned to the most frequent category, 1 to the next most frequent value, and so on. We have to define the input column name that we want to index and the output column name in which we want the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQElLVSvNCNY"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Create an indexer\n",
    "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\n",
    "\n",
    "# Indexer identifies categories in the data\n",
    "indexer_model = indexer.fit(flights_km)\n",
    "\n",
    "# Indexer creates a new column with numeric index values\n",
    "flights_indexed = indexer_model.transform(flights_km)\n",
    "\n",
    "# Repeat the process for the other categorical feature\n",
    "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ervxYO4-iu6W"
   },
   "source": [
    "*Transformers* are functions that convert raw data in some way. This might be to create a new interaction variable (from two other variables), normalize a column, or simply change an Integer into a Double type to be input into a model. An example of a transformer is one that converts string categorical variables into numerical values that can be used in MLlib. Transformers are primarily used in preprocessing and feature engineering. Transformers take a DataFrame as input and produce a new DataFrame as output, as illustrated below:\n",
    "![alt text](https://learning.oreilly.com/library/view/spark-the-definitive/9781491912201/assets/spdg_2403.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "9QZUiuDCS0bL",
    "outputId": "92cabbcc-bd1a-4d12-a3da-19ca9727d461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|        1.0|    0.0|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|        0.0|    1.0|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|        1.0|    0.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_indexed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "2q2BZwLmUy0E",
    "outputId": "34aac84e-3079-493d-e0bb-48bc6338fd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           org_idx|\n",
      "+-------+------------------+\n",
      "|  count|             47022|\n",
      "|   mean|1.6448896261324486|\n",
      "| stddev|1.8366570435032554|\n",
      "|    min|               0.0|\n",
      "|    max|               7.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_indexed.describe('org_idx').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uraSqoYM5VXv"
   },
   "source": [
    "* 0.0 --> is the most frequent value\n",
    "* 7.0 --> is the less frequent value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYyXpNEQT14A"
   },
   "source": [
    "#### Assembling columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_iCB9sPT_SK"
   },
   "source": [
    "The final stage of data preparation is to consolidate all of the predictor columns into a single column.\n",
    "\n",
    "At present our data has the following predictor columns:\n",
    "\n",
    "* mon, dom and dow\n",
    "* carrier_idx (derived from carrier)\n",
    "* org_idx (derived from org)\n",
    "* km\n",
    "* depart\n",
    "* duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t03aeMLmVVWH"
   },
   "source": [
    "**A vector assembler** combines a given list of columns into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "E37Aikj9S2my",
    "outputId": "8a4b8e86-c58b-4346-ebf3-ed488c7e44b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |label|\n",
      "+-----------------------------------------+-----+\n",
      "|[0.0,22.0,2.0,0.0,0.0,509.0,16.33,82.0]  |1    |\n",
      "|[2.0,20.0,4.0,0.0,1.0,542.0,6.17,82.0]   |0    |\n",
      "|[9.0,13.0,1.0,1.0,0.0,1989.0,10.33,195.0]|0    |\n",
      "|[5.0,2.0,1.0,0.0,1.0,885.0,7.98,102.0]   |0    |\n",
      "|[7.0,2.0,6.0,1.0,0.0,1180.0,10.83,135.0] |1    |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the VectorAssembler class\n",
    "# we use a vector assembler to transform the data.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=['mon', 'dom', 'dow', 'carrier_idx', \n",
    "                                       'org_idx', 'km', 'depart', 'duration'], \n",
    "                            outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights_assembled = assembler.transform(flights_indexed)\n",
    "\n",
    "# Check the resulting column\n",
    "flights_assembled.select('features', 'label').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyVyZFmNHHV9"
   },
   "source": [
    "## Classification\n",
    "Predict whether or not a given flight will be delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gfzJyuMVkbx"
   },
   "source": [
    "### Decision Tree\n",
    "Decision tree is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fjV16AfyaKM-"
   },
   "source": [
    "![alt text]('DT.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0il435PaguD"
   },
   "source": [
    "#### Classifying flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "FKALZzzgVfHf",
    "outputId": "96f4c8cf-95a5-449d-8071-81cc511a511b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|[0.0,22.0,2.0,0.0...|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|[2.0,20.0,4.0,0.0...|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|        1.0|    0.0|[9.0,13.0,1.0,1.0...|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|        0.0|    1.0|[5.0,2.0,1.0,0.0,...|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|        1.0|    0.0|[7.0,2.0,6.0,1.0,...|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_assembled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBpfIB2sa3Zd"
   },
   "source": [
    "#### Split train/test\n",
    "Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKQg8UxbawdD"
   },
   "outputs": [],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=17)\n",
    "flights_train = flights_train.select(['features', 'label'])\n",
    "flights_test = flights_test.select(['features', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IKaq-Tr3ct5j",
    "outputId": "722f3e54-afb6-44ac-cbce-474aa6fd67f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980732423121092\n"
     ]
    }
   ],
   "source": [
    "# Check that training set has around 80% of records\n",
    "training_ratio = flights_train.count() / flights.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wYQ713Bxc1Ns"
   },
   "source": [
    "#### Build a Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLsqYVINc9kf"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_lHz8BBjdC95"
   },
   "source": [
    "Create a Decision Tree classier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6i89LwJc_un"
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjNkjBLodoKT"
   },
   "source": [
    "Learn from the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQ3LBl5GdG8O"
   },
   "outputs": [],
   "source": [
    "tree = tree.fit(flights_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aaT8WIsid1QC"
   },
   "source": [
    "#### Evaluating the DT model\n",
    "Make predictions on the testing data and aompare to known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2AsfZcPdvm5"
   },
   "outputs": [],
   "source": [
    "prediction = tree.transform(flights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "TJEPi7y-eDBW",
    "outputId": "d17ab19e-df4f-49e1-d857-c8b5faa25c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|1    |1.0       |[0.48838709677419356,0.5116129032258064]|\n",
      "|1    |1.0       |[0.3543011744450593,0.6456988255549406] |\n",
      "|1    |1.0       |[0.3543011744450593,0.6456988255549406] |\n",
      "|1    |1.0       |[0.3543011744450593,0.6456988255549406] |\n",
      "|1    |1.0       |[0.3543011744450593,0.6456988255549406] |\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTHnalCYenfQ"
   },
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IbWtZZZ5fzrW"
   },
   "source": [
    "A confusion matrix gives a useful breakdown of predictions versus known values. It has four cells which represent the counts of:\n",
    "\n",
    "* True Negatives (TN) — model predicts negative outcome & known outcome is negative\n",
    "* True Positives (TP) — model predicts positive outcome & known outcome is positive\n",
    "* False Negatives (FN) — model predicts negative outcome but known outcome is positive\n",
    "* False Positives (FP) — model predicts positive outcome but known outcome is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "dJmJPSfbeGh2",
    "outputId": "fae53b61-e4bd-4977-c452-059e029bac7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1087|\n",
      "|    0|       0.0| 2286|\n",
      "|    1|       1.0| 3737|\n",
      "|    0|       1.0| 2385|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.groupby(\"label\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rU5kzkx4ebt7"
   },
   "outputs": [],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label = 1').count()\n",
    "FP = prediction.filter('prediction = 1 AND label = 0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wcB7lk5Fe9Ue"
   },
   "source": [
    "##### Accuracy\n",
    "Accuracy is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right. Formally, accuracy has the following definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUNWL55RgsVh"
   },
   "source": [
    "$$Accuracy = \\frac{(TN + TP)}{(TN + TP + FN + FP)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-lY0WunogqIp",
    "outputId": "8d47aedc-162e-4d70-c680-fbcc3c0d6172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634333859926277\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP)/(TN+ TP+ FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yV9L9xCyhJVR"
   },
   "source": [
    "### Logistic Regression\n",
    "In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick. This can be extended to model several classes of events such as determining whether an image contains a cat, dog, lion, etc. Each object being detected in the image would be assigned a probability between 0 and 1 and the sum adding to one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GRcvzsQylmvQ"
   },
   "source": [
    "#### Build a logistic Regreesion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZwyVMGkgrmZ"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SB7uODK5lzL-"
   },
   "source": [
    "**Create a logistic Regression classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vn2fh_92lyNv"
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EuiAMY-il-yH"
   },
   "source": [
    "**Learn from the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bS4Ku4ddmC00"
   },
   "outputs": [],
   "source": [
    "logistic = logistic.fit(flights_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywvquDXLmMiU"
   },
   "source": [
    "**Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMpIYGczmKcE"
   },
   "outputs": [],
   "source": [
    "prediction = logistic.transform(flights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "rljKfM1OmYU1",
    "outputId": "f6bdb16e-3a8e-4708-d44b-35b6137ade29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|1    |0.0       |[0.5033470048952998,0.49665299510470023]|\n",
      "|1    |1.0       |[0.35967532714510964,0.6403246728548905]|\n",
      "|1    |1.0       |[0.3071406970789145,0.6928593029210856] |\n",
      "|1    |1.0       |[0.2149373998372294,0.7850626001627706] |\n",
      "|1    |1.0       |[0.2742323639584431,0.7257676360415569] |\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "Q4dftjW9oH50",
    "outputId": "49b0e663-2337-4d77-9f69-80f5560af1bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 1652|\n",
      "|    0|       0.0| 2645|\n",
      "|    1|       1.0| 3172|\n",
      "|    0|       1.0| 2026|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "prediction.groupby('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXFxh0T9m2Jw"
   },
   "source": [
    "#### Evaluate the Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhrUQOuEffCf"
   },
   "source": [
    "##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8_k7qLdovgz"
   },
   "outputs": [],
   "source": [
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label = 1').count()\n",
    "FP = prediction.filter('prediction = 1 AND label = 0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8-3530BflWQ"
   },
   "source": [
    "##### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_XqZ-wLf85h"
   },
   "source": [
    "Precision attempts to answer the following question:\n",
    "\n",
    "\n",
    "*What proportion of positive identifications was actually correct?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WdOKg1zozgd"
   },
   "source": [
    "$$Precision (positive) = \\frac{TP}{(TP + FP)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZQB2drRfur0"
   },
   "source": [
    "##### Recall\n",
    "Recall attempts to answer the following question:\n",
    "\n",
    "*What proportion of actual positives was identified correctly?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZNj4hm0fxTz"
   },
   "source": [
    "\n",
    "$$Recall (positive) = \\frac{TP}{(TP + FN)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-qfSr4xJoxze",
    "outputId": "1546e765-7aca-459a-9b80-9e800d833833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.61\n",
      "recall    = 0.66\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43qBPzjvmUSq"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vhMAw_jhm_bN",
    "outputId": "d5414469-87f1-46d7-b591-bd34fd7fde13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6128474273772628"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.evaluate(prediction, {evaluator.metricName:'weightedPrecision'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HoSNe8BoDDHx"
   },
   "source": [
    "### SMS dataset\n",
    "The file sms.csv contains a selection of SMS messages which have been classified as either 'spam' or 'ham'. These data have been adapted from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). There are a total of 5574 SMS, of which 747 have been labelled as spam.\n",
    "\n",
    "Notes on CSV format:\n",
    "* no header record and\n",
    "* fields are separated by a semicolon (this is not the default separator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QbJcwAhYFi5m"
   },
   "source": [
    "#### Loading SMS spam data\n",
    "In the SMS data the header is missing. So we need to create the data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNTe4yEUF3Cn"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTbWsmayT6bf"
   },
   "source": [
    "We can define the custom schema for our dataframe in Spark. For this, we need to create an object of StructType which takes a list of StructField. And of course, we should define StructField with a column name, the data type of the column and whether null values are allowed for the particular column or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "m6bl4doUDwfL",
    "outputId": "02e44c68-c0b7-4a71-a4f5-50c9ed5111a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify column names and types\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"text\", StringType()),\n",
    "    StructField(\"label\", IntegerType())\n",
    "])\n",
    "\n",
    "# Load data from a delimited file\n",
    "sms = spark.read.csv('sms.csv', sep=';', header=False, schema=schema)\n",
    "\n",
    "# Print schema of DataFrame\n",
    "sms.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B955xm3Nq_mN"
   },
   "source": [
    "#### Turning Text into Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai-QE20LDHk4"
   },
   "source": [
    "##### Data dictionary\n",
    "id — record identifier\n",
    "\n",
    "text — content of SMS message\n",
    "\n",
    "label — spam or ham (integer; 0 = ham and 1 = spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "rwvuWCbCqtgG",
    "outputId": "04cf4898-e57b-460a-c8c0-5c69889e0d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "|id |text                              |label|words                                     |\n",
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "|1  |Sorry I'll call later in meeting  |0    |[sorry, i'll, call, later, in, meeting]   |\n",
      "|2  |Dont worry I guess he's busy      |0    |[dont, worry, i, guess, he's, busy]       |\n",
      "|3  |Call FREEPHONE now                |1    |[call, freephone, now]                    |\n",
      "|4  |Win a cash prize or a prize worth |1    |[win, a, cash, prize, or, a, prize, worth]|\n",
      "+---+----------------------------------+-----+------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary functions\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "# Remove punctuation (REGEX provided) and numbers\n",
    "wrangled = sms.withColumn('text', regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '\\d', ' '))\n",
    "\n",
    "# Merge multiple spaces\n",
    "wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n",
    "\n",
    "# Split the text into words\n",
    "wrangled = Tokenizer(inputCol='text', outputCol='words').transform(wrangled)\n",
    "\n",
    "wrangled.show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDc7mQYL0o8M"
   },
   "outputs": [],
   "source": [
    "sms = wrangled.select(['id', 'words', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "B1il76Sy0vc3",
    "outputId": "73820d01-7f69-4462-db76-daa987a352f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "| id|               words|label|\n",
      "+---+--------------------+-----+\n",
      "|  1|[sorry, i'll, cal...|    0|\n",
      "|  2|[dont, worry, i, ...|    0|\n",
      "|  3|[call, freephone,...|    1|\n",
      "|  4|[win, a, cash, pr...|    1|\n",
      "|  5|[go, until, juron...|    0|\n",
      "+---+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfqIc7TWrNhy"
   },
   "source": [
    "#### Stop Words\n",
    "A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "TYydUBRH0xLn",
    "outputId": "4d9ea6d1-658e-4fca-b96f-319e7328d9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+\n",
      "| id|               words|label|               terms|\n",
      "+---+--------------------+-----+--------------------+\n",
      "|  1|[sorry, i'll, cal...|    0|[sorry, call, lat...|\n",
      "|  2|[dont, worry, i, ...|    0|[dont, worry, gue...|\n",
      "|  3|[call, freephone,...|    1|   [call, freephone]|\n",
      "|  4|[win, a, cash, pr...|    1|[win, cash, prize...|\n",
      "|  5|[go, until, juron...|    0|[go, jurong, poin...|\n",
      "+---+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover, HashingTF, IDF\n",
    "\n",
    "# Remove stop words.\n",
    "wrangled = StopWordsRemover(inputCol='words', outputCol='terms')\\\n",
    "      .transform(sms)\n",
    "wrangled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cQSc3SsHrBWb"
   },
   "source": [
    "#### Hashing Trick\n",
    "Hashing Trick is a fast and space-efficient way of vectorizing features, i.e. turning arbitrary features into indices in a vector or matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "DmO8D8n9pbLD",
    "outputId": "c496da7c-ac2a-45e8-a5ff-a7e8a2a90b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+--------------------+\n",
      "| id|               words|label|               terms|                hash|\n",
      "+---+--------------------+-----+--------------------+--------------------+\n",
      "|  1|[sorry, i'll, cal...|    0|[sorry, call, lat...|(1024,[138,344,37...|\n",
      "|  2|[dont, worry, i, ...|    0|[dont, worry, gue...|(1024,[53,233,329...|\n",
      "|  3|[call, freephone,...|    1|   [call, freephone]|(1024,[138,396],[...|\n",
      "|  4|[win, a, cash, pr...|    1|[win, cash, prize...|(1024,[31,69,387,...|\n",
      "|  5|[go, until, juron...|    0|[go, jurong, poin...|(1024,[116,262,33...|\n",
      "+---+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the hashing trick\n",
    "wrangled = HashingTF(inputCol=\"terms\", outputCol=\"hash\", numFeatures=1024)\\\n",
    "      .transform(wrangled)\n",
    "wrangled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CmJ-ZEPqmFO"
   },
   "source": [
    "#### TFIDF\n",
    "TF-IDF (term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "4SF_CAHFpozC",
    "outputId": "5aa123f7-05f5-4598-9496-26c81af17d76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|terms                           |features                                                                                            |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|[sorry, call, later, meeting]   |(1024,[138,344,378,1006],[2.2391682769656747,2.892706319430574,3.684405173719015,4.244020961654438])|\n",
      "|[dont, worry, guess, busy]      |(1024,[53,233,329,858],[4.618714411095849,3.557143394108088,4.618714411095849,4.937168142214383])   |\n",
      "|[call, freephone]               |(1024,[138,396],[2.2391682769656747,3.3843005812686773])                                            |\n",
      "|[win, cash, prize, prize, worth]|(1024,[31,69,387,428],[3.7897656893768414,7.284881949239966,4.4671645129686475,3.898659777615979])  |\n",
      "+--------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert hashed symbols to TF-IDF\n",
    "tf_idf = IDF(inputCol='hash', outputCol='features')\\\n",
    "      .fit(wrangled).transform(wrangled)\n",
    "      \n",
    "tf_idf.select('terms', 'features').show(4, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rL582tMS7tG6"
   },
   "outputs": [],
   "source": [
    "sms = tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXXLWZUjrh5g"
   },
   "source": [
    "#### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "EE3Rb0fC6AZd",
    "outputId": "5a59f3d9-4896-4cc4-ffeb-7c18e768c649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|   47|\n",
      "|    0|       0.0|  987|\n",
      "|    1|       1.0|  124|\n",
      "|    0|       1.0|    3|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "sms_train, sms_test = sms.randomSplit([0.8, 0.2], seed = 13)\n",
    "\n",
    "# Fit a Logistic Regression model to the training data\n",
    "logistic = LogisticRegression(regParam=0.2).fit(sms_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "prediction = logistic.transform(sms_test)\n",
    "\n",
    "# Create a confusion matrix, comparing predictions to known labels\n",
    "prediction.groupBy(\"label\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVDzjX6o8Q6n"
   },
   "source": [
    "### Regression\n",
    "\n",
    "\n",
    "We want to build a regression model to predict flight duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MghexpLb8UyK"
   },
   "source": [
    "#### One-Hot Encoding\n",
    "using indexing values to convert a category type is not going to work in a regression problem. as each numeric value has different weight.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16obHjW7AFH1"
   },
   "source": [
    "##### Dummy Varaibles: sparse representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTosoNcsAKtr"
   },
   "source": [
    "**Dummy Variable**\n",
    "\n",
    "Each categorical level becomes a column.\n",
    "\n",
    "![alt text](https://www.mathworks.com/help/stats/dummy1.png)\n",
    "\n",
    "*This approach can increase the size of our dataset.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YmJHRWxxN1H"
   },
   "source": [
    "**Dummy variable: sparse representation**\n",
    "\n",
    "<img src ='/content/dumy_variable.png'/>\n",
    "\n",
    "![title]('/content/dumy_variable.png')\n",
    "\n",
    "\n",
    "Sparse representation: store column index and value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eq2ldevuyWew"
   },
   "source": [
    "##### Applying one_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRfjMG-i7pzv"
   },
   "outputs": [],
   "source": [
    "# Import the one hot encoder class\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "# Create an instance of the one hot encoder\n",
    "onehot = OneHotEncoderEstimator(inputCols=['org_idx'] , outputCols=['org_dummy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1kI_mtzzOcQ"
   },
   "outputs": [],
   "source": [
    "# Apply the one hot encoder to the flights data\n",
    "onehot = onehot.fit(flights_assembled)\n",
    "flights = onehot.transform(flights_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "e_eFWIeP0WzA",
    "outputId": "43499de0-4acf-429f-912c-a635b0d12102"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of categories\n",
    "onehot.categorySizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "9zQvfauf0ZxQ",
    "outputId": "336555a8-cb29-4ba2-fbda-ec6d7a6193cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|[0.0,22.0,2.0,0.0...|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|[2.0,20.0,4.0,0.0...|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|        1.0|    0.0|[9.0,13.0,1.0,1.0...|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|        0.0|    1.0|[5.0,2.0,1.0,0.0,...|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|        1.0|    0.0|[7.0,2.0,6.0,1.0,...|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_assembled.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "9auj9idU0uRO",
    "outputId": "6142bca9-4f98-41ba-bdad-4f6a48beec5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------------+\n",
      "|org|org_idx|    org_dummy|\n",
      "+---+-------+-------------+\n",
      "|ORD|    0.0|(7,[0],[1.0])|\n",
      "|SFO|    1.0|(7,[1],[1.0])|\n",
      "|JFK|    2.0|(7,[2],[1.0])|\n",
      "|LGA|    3.0|(7,[3],[1.0])|\n",
      "|SMF|    4.0|(7,[4],[1.0])|\n",
      "|SJC|    5.0|(7,[5],[1.0])|\n",
      "|TUS|    6.0|(7,[6],[1.0])|\n",
      "|OGG|    7.0|    (7,[],[])|\n",
      "+---+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the results\n",
    "flights.select('org', 'org_idx', 'org_dummy').distinct().sort('org_idx').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCrmfDVE4Elv"
   },
   "source": [
    "#### Regression Model\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1920px-Linear_regression.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fwrl-w7G4ydg"
   },
   "source": [
    "#### Loss Function\n",
    "How well the model is?\n",
    "\n",
    "$$MSE = \\frac{1}{N}\\sum_{i=1}^{N}(y_i - \\hat{y_i})^2$$\n",
    "\n",
    "MSE: \"Mean Square Error\"\n",
    "Where: \n",
    "\n",
    "$y_i$ -- observed values\n",
    "\n",
    "$\\hat{y_i}$ -- model value\n",
    "\n",
    "**Don't wory** the spark will do all the calculations for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXGoqJ0h7f_1"
   },
   "source": [
    "##### Build regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgrKq1UY07hk"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqPLRpxA7wnN"
   },
   "outputs": [],
   "source": [
    "# Create a regression object\n",
    "regression = LinearRegression(labelCol='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n77-qX8W8ayp"
   },
   "outputs": [],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "flights_train, flights_test = flights.randomSplit([0.8, 0.2], seed=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvY2lo9O7-m9"
   },
   "source": [
    "Fit to flight_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nC3IY5ch79P8"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "regression = regression.fit(flights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "WO-PGJgKAJPv",
    "outputId": "21813649-2a73-47ab-d60b-bd6f5a2cc282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|duration|prediction        |\n",
      "+--------+------------------+\n",
      "|240     |240.00000000000017|\n",
      "|160     |160.00000000000003|\n",
      "|130     |129.99999999999997|\n",
      "|275     |275.00000000000006|\n",
      "|85      |84.99999999999994 |\n",
      "+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create predictions for the testing data and take a look at the predictions\n",
    "predictions = regression.transform(flights_test)\n",
    "predictions.select('duration', 'prediction').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lV4qWx_7APkV",
    "outputId": "44b68c1f-de6c-4241-9b56-6b638c4fb6ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.447208869735431e-14"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "# Calculate the RMSE\n",
    "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "371gO0cg0x-4",
    "outputId": "6f84d9f0-0b48-4012-e02c-4ebf8cc1c524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|  0|  1|  2|     AA|JFK|  6.58|     230|   50|2570.0|    1|\n",
      "|  0|  1|  2|     AA|JFK|   7.0|     385|  -16|4162.0|    0|\n",
      "|  0|  1|  2|     AA|JFK|  12.0|     370|   11|3983.0|    0|\n",
      "|  0|  1|  2|     AA|JFK|  17.0|     379|  -10|3983.0|    0|\n",
      "|  0|  1|  2|     AA|LGA|  8.25|     250|   27|2235.0|    1|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_train, flights_test = flights_km.randomSplit([0.8, 0.2], seed=17)\n",
    "flights_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQNWFc_8z0Cu"
   },
   "outputs": [],
   "source": [
    "# Convert categorical strings to index values\n",
    "indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "\n",
    "# One-hot encode index values\n",
    "onehot = OneHotEncoderEstimator(\n",
    "    inputCols=['org_idx', 'dow'],\n",
    "    outputCols=['org_dummy','dow_dummy']\n",
    ")\n",
    "\n",
    "# Assemble predictors into a single column\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'], outputCol='features')\n",
    "\n",
    "# A linear regression object\n",
    "regression = LinearRegression(labelCol='duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61tBPpn8z08X"
   },
   "outputs": [],
   "source": [
    "# Import class for creating a pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Construct a pipeline\n",
    "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "pipeline = pipeline.fit(flights_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = pipeline.transform(flights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3OEPo2l00t2"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "\n",
    "# Break text into tokens at non-word characters\n",
    "tokenizer = Tokenizer(inputCol='text', outputCol='words')\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n",
    "\n",
    "# Apply the hashing trick and transform to TF-IDF\n",
    "hasher = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"hash\")\n",
    "idf = IDF(inputCol=hasher.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "# Create a logistic regression object and add everything to a pipeline\n",
    "logistic = LogisticRegression()\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hasher, idf, logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "gWbVwRkG3BF5",
    "outputId": "903929be-c453-4539-80f9-63803e1176b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|   40|\n",
      "|    0|       0.0|  989|\n",
      "|    1|       1.0|  131|\n",
      "|    0|       1.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "sms_train, sms_test = sms.randomSplit([0.8, 0.2], seed = 13)\n",
    "\n",
    "# Fit a Logistic Regression model to the training data\n",
    "pipeline = pipeline.fit(sms_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "prediction = pipeline.transform(sms_test)\n",
    "\n",
    "# Create a confusion matrix, comparing predictions to known labels\n",
    "prediction.groupBy(\"label\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fo4a_Sz93e3D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.Machine_Learning_pyspark.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
