{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.6.tgz\n",
    "!tar xvf spark-2.4.4-bin-hadoop2.6.tgz\n",
    "!pip install -q findspark\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.6\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"PySpark_dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Resilient Distributed Datasets (RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide_input",
     "remove_output"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-689f8f6177c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"PySpark_RDD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"PySpark_RDD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nu_LKAPE25Y3"
   },
   "source": [
    "## Creating RDDs. How to do it?\n",
    "RDD stands for Resilient Distributed Dataset, these are the elements that run and operate on multiple nodes to do parallel processing on a cluster. RDDs are immutable elements, which means once you create an RDD you cannot change it. RDDs are fault tolerant as well, hence in case of any failure, they recover automatically.\n",
    "\n",
    "* Parallelizing an existing collection of objects\n",
    "* External datasets:\n",
    "  * Files in HDFS\n",
    "  * Objects in Amazon S3 bucket\n",
    "  * lines in a text le\n",
    "* From existing RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNfNGIw23HPO"
   },
   "source": [
    "### Parallelized collection (parallelizing)\n",
    "* *parallelize()* for creating RDDs from python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIYM7GNR2xyr"
   },
   "outputs": [],
   "source": [
    "numRDD = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0BATxUr3wVL"
   },
   "outputs": [],
   "source": [
    "helloRDD = sc.parallelize(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9yng8Lxb31y1",
    "outputId": "33092d49-bd99-4d80-af28-ef33b18be5f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(helloRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "meOfgQnX37WE"
   },
   "source": [
    "### From external datasets\n",
    "* *textFile()* for creating RDDs from external dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbX140vc34Xb"
   },
   "outputs": [],
   "source": [
    "fileRDD = sc.textFile(\"sample_data/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6QemFATv4W0o",
    "outputId": "b046dd8a-33cb-4946-99dd-645414b991c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fileRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrvLn-oh4cQz"
   },
   "source": [
    "## Understanding Partitioning in PySpark\n",
    "* A partition is a logical division of a large distributed data set\n",
    "* *parallelize()* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_cIqTox4ZKe"
   },
   "outputs": [],
   "source": [
    "numRDD = sc.parallelize(range(10), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EOvhnsKx8DIv",
    "outputId": "ac8ff4ff-05a6-4f8e-c32c-f40026099a99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6dYU1R46JPB"
   },
   "source": [
    "* textFile() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LnuzCQoV5WCZ"
   },
   "outputs": [],
   "source": [
    "fileRDD = sc.textFile(\"sample_data/README.md\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4IllaY7L8I5s",
    "outputId": "c384b585-45cc-4da6-e514-5ac04aa2acd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2HVyv6X6Tp_"
   },
   "source": [
    "Your Turn:\n",
    "* Create an RDD named RDD from a list of words.\n",
    "* Confirm the object created is RDD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvB4HRCj6HDA"
   },
   "outputs": [],
   "source": [
    "# Create an RDD from a list of words\n",
    "RDD = sc.____([\"Spark\", \"is\", \"a\", \"framework\", \"for\", \"Big Data processing\"])\n",
    "\n",
    "# Print out the type of the created object\n",
    "print(\"The type of RDD is\", ____(RDD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NrMV6lZw6kkx"
   },
   "source": [
    "* Print the file_path.\n",
    "* Create an RDD named fileRDD from a file_path with the file name README.md.\n",
    "* Print the type of the fileRDD created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDglyPgG6sMh"
   },
   "outputs": [],
   "source": [
    "file_path = \"sample_data/README.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t2TPavAm6p2r"
   },
   "outputs": [],
   "source": [
    "# Print the file_path\n",
    "print(\"The file_path is\", ____)\n",
    "\n",
    "# Create a fileRDD from file_path\n",
    "fileRDD = sc.____(file_path)\n",
    "\n",
    "# Check the type of fileRDD\n",
    "print(\"The file type of fileRDD is\", type(____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ijzlcxl7CTy"
   },
   "source": [
    "* Find the number of partitions that support fileRDD RDD.\n",
    "* Create an RDD named fileRDD_part from the file path but create 5 partitions.\n",
    "* Confirm the number of partitions in the new fileRDD_part RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UOF07tI7WIs"
   },
   "outputs": [],
   "source": [
    "# Check the number of partitions in fileRDD\n",
    "print(\"Number of partitions in fileRDD is\", fileRDD.getNumPartitions)\n",
    "\n",
    "# Create a fileRDD_part from file_path with 5 partitions\n",
    "fileRDD_part = sc.textFile(____, ____)\n",
    "\n",
    "# Check the number of partitions in fileRDD_part\n",
    "print(\"Number of partitions in fileRDD_part is\", fileRDD_part.____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4CPwYZN8y75"
   },
   "source": [
    "## Spark operations\n",
    "spark_operations = Transformations + Actions\n",
    "* Transformations create new RDDS\n",
    "* Actions perform computation on the RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkGzo8LVA0og"
   },
   "source": [
    "### RDD Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UgncOPw9GYc"
   },
   "source": [
    "#### map() Transformation\n",
    "map() transformation applies a function to all elements in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Xn24EQ08891B",
    "outputId": "c8c6b3d2-5333-4245-cdbb-89d880ffcd69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD = sc.parallelize([1, 2, 3, 4])\n",
    "RDD_map = RDD.map(lambda x: x * x)\n",
    "# Action\n",
    "RDD_map.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTXWmjNd98a0"
   },
   "source": [
    "#### filter() Transformation\n",
    "Filter transformation returns a new RDD with only the elements that pass the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C_zC1m4Z927j",
    "outputId": "170f998b-da8e-4346-d3c5-dc80f6e80c29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD = sc.parallelize([1, 2, 3, 4])\n",
    "RDD_filter = RDD.filter(lambda x: x > 2)\n",
    "# Action\n",
    "RDD_filter.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-Px2hYg-TLE"
   },
   "source": [
    "#### flatMap()\n",
    "* flatMap() transformation returns multiple values for each element in the original RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cBKBRxER-Qlv",
    "outputId": "85ed31ff-0751-42d2-a2f2-ae58446af0ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'World', 'How', 'are', 'you']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD = sc.parallelize([\"hello World\", \"How are you\"])\n",
    "RDD_flatmap = RDD.flatMap(lambda x: x.split(\" \"))\n",
    "# Action\n",
    "RDD_flatmap.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xhiumXR5_6XE"
   },
   "source": [
    "#### Union ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEHDW7Wu-4_5"
   },
   "outputs": [],
   "source": [
    "inputRDD = sc.textFile(\"logs.txt\")\n",
    "errorRDD = inputRDD.filter(lambda x: \"error\" in x.split())\n",
    "warningsRDD = inputRDD.filter(lambda x: \"warnings\" in x.split())\n",
    "combinedRDD = errorRDD.union(warningsRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LT413eBkAumI"
   },
   "source": [
    "### RDD Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQxUAFeTBKIb"
   },
   "source": [
    "* Operation return a value after running a computation on the RDD\n",
    "* BasicRDD Actions\n",
    "  * collect()\n",
    "  * take(N)\n",
    "  * first()\n",
    "  * count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6lfCnDzBR-M"
   },
   "source": [
    "#### collect() and take() Actions\n",
    "* collect() return allthe elements ofthe dataset as an array\n",
    "* take(N) returns an array with the rst N elements ofthe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EAE90_GVBEWQ",
    "outputId": "d041b91a-d3cc-455c-bf49-546f5e0915f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_map.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vGftZhyVBycK",
    "outputId": "8bb0bceb-cedc-41f3-c836-e4397613843d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_map.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t006z6LKB411"
   },
   "source": [
    "#### first() and count() Actions\n",
    "* first() prints the first element ofthe RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IJmVj6M9B2HR",
    "outputId": "a4c3f564-7751-42e6-8c8c-2a529cf1806d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_map.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GmnzMj05B-BY",
    "outputId": "2ff1ca42-4cb9-4776-ffd2-6d80ce7d7896"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_flatmap.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vRpriy3CQEU"
   },
   "source": [
    "### Your Turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izrHBcawCTP7"
   },
   "outputs": [],
   "source": [
    "numbRDD = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-umVQ5VNCn3V"
   },
   "source": [
    "* Create map() transformation that cubes all of the numbers in numbRDD.\n",
    "* Collect the results in a numbers_all variable.\n",
    "* Print the output from numbers_all variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyKnM8v5ClJK"
   },
   "outputs": [],
   "source": [
    "# Create map() transformation to cube numbers\n",
    "cubedRDD = numbRDD.map(lambda x: ____)\n",
    "\n",
    "# Collect the results\n",
    "numbers_all = cubedRDD.____()\n",
    "\n",
    "# Print the numbers from numbers_all\n",
    "for numb in ____:\n",
    "\tprint(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DD44H6hmDGCY"
   },
   "source": [
    "* Create filter() transformation to select the lines containing the keyword Spark.\n",
    "* How many lines in fileRDD_filter contains the keyword Spark?\n",
    "* Print the first four lines of the resulting RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzFtZoeBDK8M"
   },
   "outputs": [],
   "source": [
    "fileRDD = sc.textFile('Pyspark_RDD_q1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhLpkSIwD8XV"
   },
   "outputs": [],
   "source": [
    "# Filter the fileRDD to select lines with Spark keyword\n",
    "fileRDD_filter = fileRDD.filter(lambda line: 'Spark' in ____)\n",
    "\n",
    "# How many lines are there in fileRDD?\n",
    "print(\"The total number of lines with the keyword Spark is\", fileRDD_filter.____())\n",
    "\n",
    "# Print the first four lines of fileRDD\n",
    "for line in fileRDD_filter.____(____): \n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "bVwQvkCAETP2",
    "outputId": "1ca99889-89e0-4257-f18c-472e7b96407f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of lines with the keyword Spark is 7\n",
      " 'Examples for Learning Spark',\n",
      " 'Examples for the Learning Spark book. These examples require a number of libraries and as such have long build files. We have also added a stand alone example with minimal dependencies and a small build file',\n",
      " 'These examples have been updated to run against Spark 1.3 so they may',\n",
      " 'be slightly different than the versions in your copy of \"Learning Spark\".',\n"
     ]
    }
   ],
   "source": [
    "# Filter the fileRDD to select lines with Spark keyword\n",
    "fileRDD_filter = fileRDD.filter(lambda line: 'Spark' in line)\n",
    "\n",
    "# How many lines are there in fileRDD?\n",
    "print(\"The total number of lines with the keyword Spark is\", fileRDD_filter.count())\n",
    "\n",
    "# Print the first four lines of fileRDD\n",
    "for line in fileRDD_filter.take(4): \n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7dmhL-SGsNs"
   },
   "source": [
    "## Pair RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jeizTyesG1lf"
   },
   "source": [
    "### Introduction to pair RDDs in PySpark\n",
    "* Real life datasets are usually key/value pairs\n",
    "* Each row is a key and maps to one or more values\n",
    "* PairRDD is a special data structure to work with this kind of datasets\n",
    "* PairRDD: Key is the identier and value is data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zi3OZBuRG-7c"
   },
   "source": [
    "### Creating pair RDDs\n",
    "* Two common ways to create pairRDDs\n",
    "  * From a list of key-value tuple\n",
    "  * From a regularRDD\n",
    "* Get the data into key/value form for paired RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RcG9PmR0EhTK",
    "outputId": "4056cdfe-5f4d-4586-c962-ed29441c1c99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sam', 23), ('Mary', 34), ('Peter', 25)]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tuple = [('Sam', 23), ('Mary', 34), ('Peter', 25)]\n",
    "pairRDD_tuple = sc.parallelize(my_tuple)\n",
    "pairRDD_tuple.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FluP3xGBHP7G",
    "outputId": "5fe86437-9e75-4a84-837d-10ce60815352"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sam', '23'), ('Mary', '34'), ('Peter', '25')]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = ['Sam 23', 'Mary 34','Peter 25']\n",
    "regularRDD = sc.parallelize(my_list)\n",
    "pairRDD_RDD = regularRDD.map(lambda s: (s.split(' ')[0], s.split(' ')[1]))\n",
    "pairRDD_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "po8SOqhUHu2y"
   },
   "source": [
    "### Transformations on pair RDDs\n",
    "* All regular transformations work on pairRDD\n",
    "* Have to pass functions that operate on key value pairs rather than on individual elements\n",
    "* Examples of paired RDD Transformations\n",
    "  * reduceByKey(func): Combine values with the same key\n",
    "  * groupByKey(): Group values with the same key\n",
    "  * sortByKey(): Return an RDD sorted by the key\n",
    "  * join(): Join two pairRDDs based on their key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p71RBPzzLXTI"
   },
   "source": [
    "#### reduceByKey() transformation\n",
    "* reduceByKey() transformation combines values with the same key\n",
    "* It runs parallel operations for each key in the dataset\n",
    "* It is a transformation and not action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6H2Jm_BxHgIT",
    "outputId": "5ecd0dc5-3138-4aef-9fd3-7be42fa3c194"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ronaldo', 34), ('Messi', 71), ('Neymar', 22)]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularRDD = sc.parallelize([(\"Messi\", 23), (\"Ronaldo\", 34), (\"Neymar\", 22), (\"Messi\", 24), (\"Messi\", 24)])\n",
    "pairRDD_reducebykey = regularRDD.reduceByKey(lambda x,y : x + y)\n",
    "pairRDD_reducebykey.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NShbdZykMTym"
   },
   "source": [
    "#### sortByKey() transformation\n",
    "* sortByKey() operation orders pairRDD by key\n",
    "* It returns an RDD sorted by key in ascending or descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3xe63jpxL5RR",
    "outputId": "df2f5ab1-f637-4b0d-f64d-0b7c203a32c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(71, 'Messi'), (34, 'Ronaldo'), (22, 'Neymar')]"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD_reducebykey_rev = pairRDD_reducebykey.map(lambda x: (x[1], x[0]))\n",
    "pairRDD_reducebykey_rev.sortByKey(ascending=False).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_WhUoFJqMnOD"
   },
   "source": [
    "#### groupByKey() transformation\n",
    "* groupbykey() groups all the values with the same key in the pair RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "4p9w2tLWMuKg",
    "outputId": "dc970960-004e-4c54-b80f-ac133248eab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US ['JFK', 'SFO']\n",
      "UK ['LHR']\n",
      "FR ['CDG']\n"
     ]
    }
   ],
   "source": [
    "airports = [(\"US\",\"JFK\"),(\"UK\",\"LHR\"),(\"FR\",\"CDG\"),(\"US\",\"SFO\")]\n",
    "regularRDD = sc.parallelize(airports)\n",
    "pairRDD_group = regularRDD.groupByKey().collect()\n",
    "for cont, air in pairRDD_group:\n",
    "  print(cont, list(air))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwcN9e_gNLuD"
   },
   "source": [
    "#### join() transformation\n",
    "* join() transformation joins the two pairRDDs based on their key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACwk9Z06NUu7"
   },
   "outputs": [],
   "source": [
    "RDD1 = sc.parallelize([(\"Messi\", 34),(\"Ronaldo\", 32),(\"Neymar\", 24)])\n",
    "RDD2 = sc.parallelize([(\"Ronaldo\", 80),(\"Neymar\", 120),(\"Messi\", 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-8xexQPhNcZK",
    "outputId": "61b59609-3380-4f66-9f37-a8089fb2a041"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Neymar', (24, 120)), ('Ronaldo', (32, 80)), ('Messi', (34, 100))]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD1.join(RDD2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xz7Rl3-uN0AF"
   },
   "source": [
    "### Your Turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30GFlMBZN880"
   },
   "source": [
    "* Create a pair RDD named Rdd with tuples (1,2),(3,4),(3,6),(4,5).\n",
    "* Transform the Rdd with reduceByKey() into a pair RDD Rdd_Reduced by adding the values with the same key.\n",
    "* Collect the contents of pair RDD Rdd_Reduced and iterate to print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJkYcf6sNlEp"
   },
   "outputs": [],
   "source": [
    "# Create PairRDD Rdd with key value pairs\n",
    "Rdd = sc.parallelize([____])\n",
    "\n",
    "# Apply reduceByKey() operation on Rdd\n",
    "Rdd_Reduced = Rdd.reduceByKey(lambda x, y: ____)\n",
    "\n",
    "# Iterate over the result and print the output\n",
    "for num in Rdd_Reduced.____: \n",
    "  print(\"Key {} has {} Counts\".format(____, num[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyh7u8AoObYe"
   },
   "outputs": [],
   "source": [
    "# Create PairRDD Rdd with key value pairs\n",
    "Rdd = sc.parallelize([(1,2),(3,4),(3,6),(4,5)])\n",
    "\n",
    "# Apply reduceByKey() operation on Rdd\n",
    "Rdd_Reduced = Rdd.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# Iterate over the result and print the output\n",
    "for num in Rdd_Reduced.collect(): \n",
    "  print(\"Key {} has {} Counts\".format(num[0], num[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "db4315xiOgb-"
   },
   "source": [
    "* Sort the Rdd_Reduced RDD using the key in descending order.\n",
    "* Collect the contents and iterate to print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HI5I1YShOk4e"
   },
   "outputs": [],
   "source": [
    "# Sort the reduced RDD with the key by descending order\n",
    "Rdd_Reduced_Sort = Rdd_Reduced.____(ascending=False)\n",
    "\n",
    "# Iterate over the result and print the output\n",
    "for num in Rdd_Reduced_Sort.____():\n",
    "  print(\"Key {} has {} Counts\".format(____, num[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeZFl5qlO3Ba"
   },
   "outputs": [],
   "source": [
    "# Sort the reduced RDD with the key by descending order\n",
    "Rdd_Reduced_Sort = Rdd_Reduced.sortByKey(ascending=False)\n",
    "\n",
    "# Iterate over the result and print the output\n",
    "for num in Rdd_Reduced_Sort.collect():\n",
    "  print(\"Key {} has {} Counts\".format(num[0], num[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zWgCnxfVO6Ig"
   },
   "source": [
    "## Advanced RDD Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6CWKF2dPCth"
   },
   "source": [
    "### reduce() action\n",
    "* reduce(func) action is used for aggregating the elements of a regularRDD\n",
    "* The function should be commutative (changing the order of the operands does not change the result) and associative\n",
    "* An example of reduce() action in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "E7XUKt5_PACc",
    "outputId": "a991d310-4331-420b-a977-83ff573e02fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,3,4,6]\n",
    "RDD = sc.parallelize(x)\n",
    "RDD.reduce(lambda x, y : x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ZdKJSs9PiZ9"
   },
   "source": [
    "### saveAsTextFile() action\n",
    "* saveAsTextFile() action saves RDD into a text file inside a directory with each partition as a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhzGBgnKPxyP"
   },
   "outputs": [],
   "source": [
    "RDD.saveAsTextFile(\"tempFile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "253A_t8lP9PP"
   },
   "source": [
    "* coalesce() method can be used to save RDD as a single text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OhBd6QqrP0kv"
   },
   "outputs": [],
   "source": [
    "RDD.coalesce(1).saveAsTextFile(\"tempFile2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zjxt4SdiQVs2"
   },
   "source": [
    "### Action Operation on pair RDDs\n",
    "* RDD actions available for PySpark pairRDDs\n",
    "* PairRDD actions leverage the key-value data\n",
    "* Few examples of pairRDD actions include\n",
    "  * countByKey()\n",
    "  * collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tsChoVN5Qj9K"
   },
   "source": [
    "#### countByKey() action\n",
    "* countByKey() only available for type (K,V)\n",
    "* countByKey() action counts the number of elements for each key\n",
    "* countByKey --> returns a dictionary\n",
    "* Example of countByKey() on a simple list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "RGoR9QgQQCwN",
    "outputId": "490033ae-29a1-4956-d2a5-7d5d6dff58f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 2\n",
      "b 1\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"a\", 5), (\"b\", 1), (\"a\", 1)])\n",
    "for kee, val in rdd.countByKey().items():\n",
    "  print(kee, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3lt20FmPRCKP"
   },
   "source": [
    "#### collectAsMap() action\n",
    "* collectAsMap() return the key-value pairs in the RDD as a dictionary\n",
    "* Example of collectAsMap() on a simple tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "v6_ddIsMQ2H-",
    "outputId": "7923860c-3144-4c31-c04f-0838da3e25c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 3: 4}"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([(1, 2), (3, 4)]).collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btDSUMtBRUGm"
   },
   "source": [
    "## Your Turn:\n",
    "* Use the countByKey() action on the Rdd to count the unique keys and assign the result to a variable total.\n",
    "* What is the type of total?\n",
    "* Iterate over the total and print the keys and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FZ1NbccRnBR"
   },
   "outputs": [],
   "source": [
    "RDD = sc.parallelize([(1, 2), (3, 4), (3, 6), (4, 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNSqA9NCRMLM"
   },
   "outputs": [],
   "source": [
    "# Transform the rdd with countByKey()\n",
    "total = Rdd.____()\n",
    "\n",
    "# What is the type of total?\n",
    "print(\"The type of total is\", type(____))\n",
    "\n",
    "# Iterate over the total and print the output\n",
    "for k, v in total.____(): \n",
    "  print(\"key\", ____, \"has\", ____, \"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAD2Gcy9SDoh"
   },
   "outputs": [],
   "source": [
    "# Transform the rdd with countByKey()\n",
    "total = Rdd.countByKey()\n",
    "\n",
    "# What is the type of total?\n",
    "print(\"The type of total is\", type(total))\n",
    "\n",
    "# Iterate over the total and print the output\n",
    "for k, v in total.items(): \n",
    "  print(\"key\", k, \"has\", v, \"counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JmHpTPf4Sccn"
   },
   "source": [
    "### William Shakespeare\n",
    "The volume of unstructured data (log lines, images, binary files) in existence is growing dramatically, and PySpark is an excellent framework for analyzing this type of data through RDDs. \n",
    "\n",
    "In this 3 part exercise, you will write code that calculates the most common words from Complete Works of William Shakespeare.\n",
    "\n",
    "Here are the brief steps for writing the word counting program:\n",
    "\n",
    "* Create a base RDD from Complete_Shakespeare.txt file.\n",
    "* Use RDD transformation to create a long list of words from each element of the base RDD.\n",
    "* Remove stop words from your data.\n",
    "* Create pair RDD where each element is a pair tuple of ('w', 1)\n",
    "* Group the elements of the pair RDD by key (word) and add up their values.\n",
    "* Swap the keys (word) and values (counts) so that keys is count and value is the word.\n",
    "* Finally, sort the RDD by descending order and print the 10 most frequent words and their frequencies.\n",
    "\n",
    "In this first exercise, you'll create a base RDD from Complete_Shakespeare.txt file and transform it to create a long list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szr9UacPSvp0"
   },
   "outputs": [],
   "source": [
    "file_path = 'Complete_Shakespeare.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYoA--5tTsTE"
   },
   "source": [
    "* Create an RDD called baseRDD that reads lines from file_path.\n",
    "* Transform the baseRDD into a long list of words and create a new splitRDD.\n",
    "* Count the total words in splitRDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2M1TNYDTKmy"
   },
   "outputs": [],
   "source": [
    "# Create a baseRDD from the file path\n",
    "baseRDD = ____(file_path)\n",
    "\n",
    "# Split the lines of baseRDD into words\n",
    "splitRDD = baseRDD.____(lambda x: x.____())\n",
    "\n",
    "# Count the total number of words\n",
    "print(\"Total number of words in splitRDD:\", splitRDD.____())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQny9JYcTlww"
   },
   "outputs": [],
   "source": [
    "# Create a baseRDD from the file path\n",
    "baseRDD = sc.textFile(file_path)\n",
    "\n",
    "# Split the lines of baseRDD into words\n",
    "splitRDD = baseRDD.flatMap(lambda x: x.split())\n",
    "\n",
    "# Count the total number of words\n",
    "print(\"Total number of words in splitRDD:\", splitRDD.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64pqR-htUF8Y"
   },
   "source": [
    "### Remove stop words (reduce the dataset)\n",
    "Stop words are common words that are often uninteresting. For example \"I\", \"the\", \"a\" etc., are stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVWirNbCULDw"
   },
   "outputs": [],
   "source": [
    "stop_words  = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will', 'just', 'don', 'should', 'now']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4ptvAPdVbL6"
   },
   "source": [
    "* Convert the words in splitRDD in lower case and then remove stop words from stop_words.\n",
    "* Create a pair RDD tuple containing the word and the number 1 from each word element in splitRDD.\n",
    "* Get the count of the number of occurrences of each word (word frequency) in the pair RDD using reduceByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0oooAN5WRW0"
   },
   "outputs": [],
   "source": [
    "# Convert the words in lower case and remove stop words from stop_words\n",
    "splitRDD_no_stop = splitRDD.____(lambda x: x.lower() not in ____)\n",
    "\n",
    "# Create a tuple of the word and 1 \n",
    "splitRDD_no_stop_words = splitRDD_no_stop.map(lambda w: (____, ____))\n",
    "\n",
    "# Count of the number of occurences of each word\n",
    "resultRDD = splitRDD_no_stop_words.____(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a73aUx8gVVgq"
   },
   "outputs": [],
   "source": [
    "# Convert the words in lower case and remove stop words from stop_words\n",
    "splitRDD_no_stop = splitRDD.filter(lambda x: x.lower() not in stop_words)\n",
    "\n",
    "# Create a tuple of the word and 1 \n",
    "splitRDD_no_stop_words = splitRDD_no_stop.map(lambda w: (w, 1))\n",
    "\n",
    "# Count of the number of occurences of each word\n",
    "resultRDD = splitRDD_no_stop_words.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2_mRcrPWxid"
   },
   "source": [
    "### Print word frequencies\n",
    "\n",
    "* Print the first 10 words and their frequencies from the resultRDD.\n",
    "* Swap the keys and values in the resultRDD.\n",
    "* Sort the keys according to descending order.\n",
    "* Print the top 10 most frequent words and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSvnCA8LW-dy"
   },
   "outputs": [],
   "source": [
    "# Display the first 10 words and their frequencies\n",
    "for word in resultRDD.____(10):\n",
    "\tprint(word)\n",
    "\n",
    "# Swap the keys and values \n",
    "resultRDD_swap = resultRDD.____(lambda x: (x[____], x[____]))\n",
    "\n",
    "# Sort the keys in descending order\n",
    "resultRDD_swap_sort = resultRDD_swap.____(ascending=False)\n",
    "\n",
    "# Show the top 10 most frequent words and their frequencies\n",
    "for word in resultRDD_swap_sort.____(____):\n",
    "\tprint(\"{} has {} counts\". format(____, word[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9DbJDS3XqV_"
   },
   "outputs": [],
   "source": [
    "# Display the first 10 words and their frequencies\n",
    "for word in resultRDD.take(10):\n",
    "\tprint(word)\n",
    "\n",
    "# Swap the keys and values \n",
    "resultRDD_swap = resultRDD.map(lambda x: (x[1], x[0]))\n",
    "\n",
    "# Sort the keys in descending order\n",
    "resultRDD_swap_sort = resultRDD_swap.sortByKey(ascending=False)\n",
    "\n",
    "# Show the top 10 most frequent words and their frequencies\n",
    "for word in resultRDD_swap_sort.take(10):\n",
    "\tprint(\"{} has {} counts\". format(word[1], word[0]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.Pyspark_RDD.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
